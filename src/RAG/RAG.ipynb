{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:06:52.534235Z",
     "start_time": "2023-11-25T08:06:52.514168Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "YourAPIKey = \"\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640e19e3961c5559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:06:53.629849Z",
     "start_time": "2023-11-25T08:06:52.521264Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33597feb02573078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:06:53.663555Z",
     "start_time": "2023-11-25T08:06:53.630098Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=(), openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce645e118f29cf79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:06:53.686887Z",
     "start_time": "2023-11-25T08:06:53.664778Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_dir = '/amos2023ws05-pipeline-config-chat-ai/src/RAG/pipelines'\n",
    "docs = []\n",
    "\n",
    "# Go through each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Load up the file as a doc and split\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e41366a23e6224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:06:53.687897Z",
     "start_time": "2023-11-25T08:06:53.685060Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 190 documents\n",
      "\n",
      "------ Start Document ------\n",
      "# Copyright 2022 RTDIP\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#      http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed \n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(docs)} documents\\n\")\n",
    "print (\"------ Start Document ------\")\n",
    "print (docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9847352294eee40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:06:57.051920Z",
     "start_time": "2023-11-25T08:06:53.687581Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90fd0d8a51a5cf31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:06:59.831522Z",
     "start_time": "2023-11-25T08:06:59.822748Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get our retriever ready\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103f11e7d6f49f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:11:12.280923Z",
     "start_time": "2023-11-25T08:10:35.004427Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"I would like to use RTDIP components to read from an eventhub using 'connection string' as the connection string, and 'consumer group' as the consumer group, transform using binary to string, and edge x transformer then write to delta, generate only code without text \"\n",
    "output = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b73d941ef97f4bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T08:11:13.673641Z",
     "start_time": "2023-11-25T08:11:13.668368Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's an example of how you can use RTDIP components to read from an Eventhub using a connection string and consumer group, transform the data from binary to string, and then write it to a Delta table:\n",
      "\n",
      "```python\n",
      "from rtdip_sdk.pipelines.sources import SparkEventhubSource\n",
      "from rtdip_sdk.pipelines.transforms import BinaryToStringTransformer, EdgeXTransformer\n",
      "from rtdip_sdk.pipelines.destinations import DeltaDestination\n",
      "from rtdip_sdk.pipelines.utilities import SparkSessionUtility\n",
      "\n",
      "# Not required if using Databricks\n",
      "spark = SparkSessionUtility(config={}).execute()\n",
      "\n",
      "# Eventhub connection string and consumer group\n",
      "connection_string = \"YOUR_EVENTHUB_CONNECTION_STRING\"\n",
      "consumer_group = \"YOUR_CONSUMER_GROUP\"\n",
      "\n",
      "# Create the Eventhub source\n",
      "eventhub_source = SparkEventhubSource(spark=spark, options={\"eventhubs.connectionString\": connection_string, \"eventhubs.consumerGroup\": consumer_group})\n",
      "\n",
      "# Read from Eventhub\n",
      "data = eventhub_source.read_stream()\n",
      "\n",
      "# Transform data from binary to string\n",
      "binary_to_string_transformer = BinaryToStringTransformer()\n",
      "transformed_data = binary_to_string_transformer.transform(data)\n",
      "\n",
      "# Apply EdgeX transformation\n",
      "edgex_transformer = EdgeXTransformer()\n",
      "transformed_data = edgex_transformer.transform(transformed_data)\n",
      "\n",
      "# Write transformed data to Delta table\n",
      "delta_destination = DeltaDestination(spark=spark, data=transformed_data, table_name=\"YOUR_DELTA_TABLE_NAME\")\n",
      "delta_destination.write_stream()\n",
      "```\n",
      "\n",
      "Make sure to replace `YOUR_EVENTHUB_CONNECTION_STRING`, `YOUR_CONSUMER_GROUP`, and `YOUR_DELTA_TABLE_NAME` with your actual values.\n",
      "\n",
      "This code will create a streaming pipeline that reads data from an Eventhub, transforms it using binary to string and EdgeX transformations, and then writes the transformed data to a Delta table.\n",
      "\n",
      "Note that you'll need to have the necessary dependencies installed and import the required modules for the components to work properly.\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7c77f0c6f47f2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
